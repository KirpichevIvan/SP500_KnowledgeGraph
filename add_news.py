import pandas as pd
import os
import time
from tqdm import tqdm
from neo4j import GraphDatabase
from langchain_ollama import OllamaEmbeddings
from langchain_community.vectorstores import Neo4jVector
from dotenv import load_dotenv

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
load_dotenv()

NEO4J_URI = os.getenv("NEO4J_URI", "bolt://localhost:7687")
NEO4J_USER = os.getenv("NEO4J_USERNAME", "neo4j")
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD", "password")

# –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏
NEWS_CSV_PATH = "../data/classified_reuters_news_mapped.csv"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
# –ü–æ—Ä–æ–≥ –¥–ª—è –ò–Ω–¥—É—Å—Ç—Ä–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, "Software" ~ "Software Services")
INDUSTRY_SIMILARITY_THRESHOLD = 0.82 
# –ü–æ—Ä–æ–≥ –¥–ª—è –ö–æ–º–ø–∞–Ω–∏–π (—Å—Ç—Ä–æ–∂–µ, —á—Ç–æ–±—ã "Apple" –Ω–µ –ª–∏–Ω–∫–æ–≤–∞–ª–∞—Å—å –∫ –Ω–æ–≤–æ—Å—Ç—è–º –ø—Ä–æ –µ–¥—É)
COMPANY_SIMILARITY_THRESHOLD = 0.75

driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
embeddings = OllamaEmbeddings(model="qwen3-embedding:0.6b")

# ==========================================
# 1. –û–ß–ò–°–¢–ö–ê
# ==========================================
def clean_graph():
    print("\nüßπ –≠–¢–ê–ü 1: –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π...")
    with driver.session() as session:
        # 1. –£–¥–∞–ª—è–µ–º –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏ –∏—Ö —Å–≤—è–∑–∏
        session.run("MATCH (n:News) DETACH DELETE n")
        print("   ‚úÖ –í—Å–µ —É–∑–ª—ã :News —É–¥–∞–ª–µ–Ω—ã.")
        
        # 2. –£–¥–∞–ª—è–µ–º –æ—à–∏–±–æ—á–Ω—ã–µ –∏–Ω–¥—É—Å—Ç—Ä–∏–∏ (—É –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç —Å–≤—è–∑–µ–π —Å –°–µ–∫—Ç–æ—Ä–∞–º–∏ –∏–ª–∏ –ö–æ–º–ø–∞–Ω–∏—è–º–∏)
        # –≠—Ç–æ —É–±–µ—Ä–µ—Ç –º—É—Å–æ—Ä, –µ—Å–ª–∏ –æ–Ω –æ—Å—Ç–∞–ª—Å—è –æ—Ç –ø—Ä–æ—à–ª—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤
        result = session.run("""
            MATCH (i:Industry)
            WHERE NOT (i)--() 
            DELETE i
            RETURN count(i) as count
        """)
        count = result.single()['count']
        print(f"   ‚úÖ –£–¥–∞–ª–µ–Ω–æ {count} '–æ—Å–∏—Ä–æ—Ç–µ–≤—à–∏—Ö' –∏–Ω–¥—É—Å—Ç—Ä–∏–π.")

# ==========================================
# 2. –ü–û–î–ì–û–¢–û–í–ö–ê –í–ï–ö–¢–û–†–û–í (–î–õ–Ø –õ–ò–ù–ö–û–í–ö–ò)
# ==========================================
def prepare_internal_indexes():
    print("\nüß† –≠–¢–ê–ü 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤–µ–∫—Ç–æ—Ä–æ–≤ –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –ø–æ–∏—Å–∫–∞...")
    
    with driver.session() as session:
        # --- –ê. –ò–Ω–¥—É—Å—Ç—Ä–∏–∏ ---
        print("   üîπ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ò–Ω–¥—É—Å—Ç—Ä–∏–π...")
        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, —É –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å –∏–º—è (—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –≤ –≥—Ä–∞—Ñ–µ)
        result = session.run("MATCH (i:Industry) WHERE i.name IS NOT NULL RETURN i.name as name")
        industries = [r["name"] for r in result]
        
        if industries:
            vectors = embeddings.embed_documents(industries)
            for name, vector in zip(industries, vectors):
                session.run("MATCH (i:Industry {name: $name}) SET i.embedding = $vec", name=name, vec=vector)
            
            # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å
            dim = len(vectors[0])
            session.run(f"""
                CREATE VECTOR INDEX industry_name_index IF NOT EXISTS
                FOR (i:Industry) ON (i.embedding)
                OPTIONS {{indexConfig: {{`vector.dimensions`: {dim}, `vector.similarity_function`: 'cosine'}}}}
            """)
        
        # --- –ë. –ö–æ–º–ø–∞–Ω–∏–∏ ---
        print("   üîπ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ö–æ–º–ø–∞–Ω–∏–π...")
        result = session.run("MATCH (c:Company) RETURN c.ticker as ticker, c.name as name")
        companies = [r for r in result]
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É: "Company: Microsoft, Ticker: MSFT" –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞
        comp_texts = [f"Company: {c['name']}, Ticker: {c['ticker']}" for c in companies]
        
        if comp_texts:
            comp_vectors = embeddings.embed_documents(comp_texts)
            for r, vector in zip(companies, comp_vectors):
                session.run("MATCH (c:Company {ticker: $t}) SET c.company_embedding = $vec", t=r['ticker'], vec=vector)
            
            # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å
            dim = len(comp_vectors[0])
            session.run(f"""
                CREATE VECTOR INDEX company_entity_index IF NOT EXISTS
                FOR (c:Company) ON (c.company_embedding)
                OPTIONS {{indexConfig: {{`vector.dimensions`: {dim}, `vector.similarity_function`: 'cosine'}}}}
            """)
            
    # –î–∞–µ–º –±–∞–∑–µ –ø–∞—Ä—É —Å–µ–∫—É–Ω–¥ –Ω–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤
    time.sleep(2)
    print("   ‚úÖ –ò–Ω–¥–µ–∫—Å—ã industry_name_index –∏ company_entity_index –≥–æ—Ç–æ–≤—ã.")

# ==========================================
# 3. –ó–ê–ì–†–£–ó–ö–ê –ò –ü–†–ò–í–Ø–ó–ö–ê –ö –ò–ù–î–£–°–¢–†–ò–Ø–ú
# ==========================================
def ingest_news():
    print("\nüì∞ –≠–¢–ê–ü 3: –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–∏–≤—è–∑–∫–∞ –∫ –∏–Ω–¥—É—Å—Ç—Ä–∏—è–º...")
    
    # –ß—Ç–µ–Ω–∏–µ CSV
    try:
        df = pd.read_csv(NEWS_CSV_PATH)
    except:
        df = pd.read_csv(NEWS_CSV_PATH, sep=';')
    df = df.fillna("")
    
    # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –°–Ω–∞—á–∞–ª–∞ –Ω–∞–π–¥–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –¥–ª—è –≤—Å–µ—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏–∑ CSV
    # –ß—Ç–æ–±—ã –Ω–µ –¥–µ—Ä–≥–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–∞ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–µ
    all_categories_raw = []
    for x in df['GICS_Subsectors_Mapped']:
        if x:
            all_categories_raw.extend([s.strip() for s in str(x).split(';') if s.strip()])
    
    unique_cats = list(set(all_categories_raw))
    print(f"   –ù–∞–π–¥–µ–Ω–æ {len(unique_cats)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤ CSV. –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –≤ –≥—Ä–∞—Ñ–µ...")
    
    cat_mapping = {} # {'CSV Category': 'Graph Industry Name'}
    
    with driver.session() as session:
        # –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        if unique_cats:
            cat_vectors = embeddings.embed_documents(unique_cats)
            
            for cat_name, vector in zip(unique_cats, cat_vectors):
                # –ò—â–µ–º –±–ª–∏–∂–∞–π—à—É—é –∏–Ω–¥—É—Å—Ç—Ä–∏—é
                res = session.run("""
                    CALL db.index.vector.queryNodes('industry_name_index', 1, $vector)
                    YIELD node, score
                    WHERE score >= $thresh
                    RETURN node.name as name
                """, vector=vector, thresh=INDUSTRY_SIMILARITY_THRESHOLD)
                
                match = res.single()
                if match:
                    cat_mapping[cat_name] = match['name']

    print(f"   –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ {len(cat_mapping)} –∏–∑ {len(unique_cats)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π.")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π
    with driver.session() as session:
        count_linked = 0
        for _, row in tqdm(df.iterrows(), total=len(df), desc="Ingesting"):
            # –†–∞–∑–±–∏–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É —Å–µ–∫—Ç–æ—Ä–æ–≤
            raw_cats = str(row['GICS_Subsectors_Mapped'])
            csv_cats_list = [s.strip() for s in raw_cats.split(';') if s.strip()]
            
            # –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ CSV-–∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤ —Å–ø–∏—Å–æ–∫ –∏–º–µ–Ω –∏–∑ –ì—Ä–∞—Ñ–∞ (—á–µ—Ä–µ–∑ –Ω–∞—à –º–∞–ø–ø–∏–Ω–≥)
            target_industries = [cat_mapping[c] for c in csv_cats_list if c in cat_mapping]
            # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            target_industries = list(set(target_industries))
            
            query = """
            MERGE (n:News {headline: $headline})
            SET n.date = $date, 
                n.description = $desc,
                n.full_text = $headline + '\n' + $desc
            
            WITH n
            UNWIND $targets AS ind_name
            MATCH (i:Industry {name: ind_name})
            MERGE (n)-[:RELATES_TO_INDUSTRY]->(i)
            """
            
            session.run(query, 
                        headline=row['Headlines'], 
                        date=row['Time'], 
                        desc=row['Description'],
                        targets=target_industries)
            
            if target_industries:
                count_linked += 1
                
    print(f"   ‚úÖ –ù–æ–≤–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –ü—Ä–∏–≤—è–∑–∞–Ω–æ –∫ –∏–Ω–¥—É—Å—Ç—Ä–∏—è–º: {count_linked}")

# ==========================================
# 4. –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–ò–í–Ø–ó–ö–ê –ö –ö–û–ú–ü–ê–ù–ò–Ø–ú
# ==========================================
def link_companies_semantic():
    print("\nüîó –≠–¢–ê–ü 4: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–∏–≤—è–∑–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∫ –∫–æ–º–ø–∞–Ω–∏—è–º...")
    
    BATCH_SIZE = 100
    
    with driver.session() as session:
        # –ü–æ–ª—É—á–∞–µ–º ID –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π, —É –∫–æ—Ç–æ—Ä—ã—Ö –µ—â–µ –Ω–µ—Ç —Å–≤—è–∑–∏ —Å –∫–æ–º–ø–∞–Ω–∏–µ–π
        result = session.run("""
            MATCH (n:News) 
            WHERE NOT (n)-[:MENTIONS]->(:Company)
            RETURN elementId(n) as id, n.headline as headline
        """)
        news_items = [r for r in result]
        
        print(f"   –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(news_items)} –Ω–æ–≤–æ—Å—Ç–µ–π...")
        links_created = 0
        
        for i in tqdm(range(0, len(news_items), BATCH_SIZE), desc="Linking Companies"):
            batch = news_items[i:i+BATCH_SIZE]
            ids = [item['id'] for item in batch]
            headlines = [item['headline'] for item in batch]
            
            # –°—á–∏—Ç–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            vectors = embeddings.embed_documents(headlines)
            
            for news_id, vector in zip(ids, vectors):
                # –ò—â–µ–º –±–ª–∏–∂–∞–π—à—É—é –∫–æ–º–ø–∞–Ω–∏—é
                # –í–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å company_entity_index –º—ã —Å–æ–∑–¥–∞–ª–∏ –Ω–∞ —ç—Ç–∞–ø–µ 2
                res = session.run("""
                    CALL db.index.vector.queryNodes('company_entity_index', 1, $vector)
                    YIELD node, score
                    WHERE score >= $thresh
                    RETURN node.ticker as ticker
                """, vector=vector, thresh=COMPANY_SIMILARITY_THRESHOLD)
                
                match = res.single()
                if match:
                    # –°–æ–∑–¥–∞–µ–º —Å–≤—è–∑—å
                    session.run("""
                        MATCH (n:News), (c:Company {ticker: $ticker})
                        WHERE elementId(n) = $nid
                        MERGE (n)-[:MENTIONS]->(c)
                    """, nid=news_id, ticker=match['ticker'])
                    links_created += 1
                    
    print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ {links_created} —Å–≤—è–∑–µ–π News -> Company.")

# ==========================================
# 5. –§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–û–î–ì–û–¢–û–í–ö–ê –î–õ–Ø RAG
# ==========================================
def setup_rag():
    print("\nüöÄ –≠–¢–ê–ü 5: –°–±–æ—Ä–∫–∞ –µ–¥–∏–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è RAG...")
    
    with driver.session() as session:
        # –†–∞—Å—Å—Ç–∞–≤–ª—è–µ–º –º–µ—Ç–∫–∏ –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞
        print("   –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–≤–æ–π—Å—Ç–≤ search_text...")
        session.run("""
            MATCH (c:Company) SET c:Searchable 
            SET c.search_text = "Company: " + c.name + "\nDescription: " + c.description
        """)
        session.run("""
            MATCH (n:News) SET n:Searchable
            SET n.search_text = "News Date: " + toString(n.date) + "\nHeadline: " + n.headline + "\nContent: " + n.description
        """)
    
    print("   –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ (unified_knowledge_index)...")
    # –≠—Ç–æ —Å–æ–∑–¥–∞—Å—Ç –∏–Ω–¥–µ–∫—Å –ø–æ –º–µ—Ç–∫–µ :Searchable –∏ –ø–æ—Å—á–∏—Ç–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è search_text
    # –ú–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è, —Ç–∞–∫ –∫–∞–∫ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Å—ë
    try:
        Neo4jVector.from_existing_graph(
            embedding=embeddings,
            url=NEO4J_URI,
            username=NEO4J_USER,
            password=NEO4J_PASSWORD,
            index_name="unified_knowledge_index",
            node_label="Searchable",
            text_node_properties=["search_text"],
            embedding_node_property="embedding",
        )
        print("   ‚úÖ Unified Index –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
    except Exception as e:
        print(f"   ‚ö†Ô∏è –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –∏–Ω–¥–µ–∫—Å–∞ (–æ–±—ã—á–Ω–æ OK, –µ—Å–ª–∏ –æ–Ω –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è): {e}")

# ==========================================
# MAIN
# ==========================================
if __name__ == "__main__":
    start_time = time.time()
    
    clean_graph()               # 1. –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä–æ–µ
    prepare_internal_indexes()  # 2. –°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –ª–∏–Ω–∫–æ–≤–∫–∏
    ingest_news()               # 3. –ó–∞–≥—Ä—É–∑–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –∏ –ª–∏–Ω–∫–æ–≤–∞—Ç—å –ò–Ω–¥—É—Å—Ç—Ä–∏–∏
    link_companies_semantic()   # 4. –õ–∏–Ω–∫–æ–≤–∞—Ç—å –ö–æ–º–ø–∞–Ω–∏–∏
    setup_rag()                 # 5. –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–ª—è —á–∞—Ç-–±–æ—Ç–∞
    
    print(f"\nüéâ –í–°–ï –ì–û–¢–û–í–û! –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {(time.time() - start_time):.2f} —Å–µ–∫.")