{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc00dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ –ù–∞—á–∏–Ω–∞—é —Å–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...\n",
      "–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è, –µ—Å–ª–∏ –∫–æ–º–ø–∞–Ω–∏–π –º–Ω–æ–≥–æ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from operator import itemgetter\n",
    "from neo4j import GraphDatabase\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∏\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\", \"bolt://localhost:7687\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USERNAME\", \"neo4j\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\", \"password\")\n",
    "BENCHMARK_FILE = \"benchmark_qa.csv\"  # –§–∞–π–ª –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —à–∞–≥–∞\n",
    "RESULTS_FILE = \"benchmark_results.csv\"\n",
    "\n",
    "\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "llm = ChatOllama(model=\"qwen3:8b\", temperature=0)\n",
    "evaluator_llm = ChatOllama(model=\"qwen3:8b\", temperature=0) \n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"qwen3-embedding:0.6b\"\n",
    ")\n",
    "\n",
    "# 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–¥–æ–ª–∂–Ω–∞ —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å —Ç–æ–π, —á—Ç–æ –±—É–¥–µ—Ç –ø—Ä–∏ –ø–æ–∏—Å–∫–µ)\n",
    "print(\"‚è≥ –ù–∞—á–∏–Ω–∞—é —Å–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...\")\n",
    "print(\"–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è, –µ—Å–ª–∏ –∫–æ–º–ø–∞–Ω–∏–π –º–Ω–æ–≥–æ...\")\n",
    "\n",
    "vector_store = Neo4jVector.from_existing_index(\n",
    "    embedding=embeddings,\n",
    "    index_name=\"global_knowledge_index\",\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USER,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    node_label=\"Searchable\",\n",
    "    text_node_property=\"description\",\n",
    "    embedding_node_property=\"embedding\"\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a4e0d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG-—Ü–µ–ø–æ—á–∫–∞ —Å–æ–±—Ä–∞–Ω–∞ –Ω–∞ LCEL.\n"
     ]
    }
   ],
   "source": [
    "rag_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "–¢—ã —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –¢–û–õ–¨–ö–û –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.\n",
    "–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç, –æ—Ç–≤–µ—Ç—å \"I don't know based on the context\".\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\n",
    "\"\"\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# –≠—Ç–∞ –º–∞–≥–∏—è LCEL –¥–µ–ª–∞–µ—Ç —Å–ª–µ–¥—É—é—â–µ–µ:\n",
    "# 1. –ü—Ä–∏–Ω–∏–º–∞–µ—Ç {\"input\": \"–≤–æ–ø—Ä–æ—Å\"}\n",
    "# 2. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ:\n",
    "#    - –ò—â–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã —á–µ—Ä–µ–∑ retriever -> –∫–ª–∞–¥–µ—Ç –≤ –∫–ª—é—á 'context'\n",
    "#    - –ü—Ä–æ–∫–∏–¥—ã–≤–∞–µ—Ç –≤–æ–ø—Ä–æ—Å -> –∫–ª–∞–¥–µ—Ç –≤ –∫–ª—é—á 'input'\n",
    "# 3. .assign –≤—ã—á–∏—Å–ª—è–µ—Ç –∫–ª—é—á 'answer', –∏—Å–ø–æ–ª—å–∑—É—è –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –≤–æ–ø—Ä–æ—Å\n",
    "rag_chain = RunnableParallel(\n",
    "    {\"context\":  itemgetter(\"input\") | retriever, \"input\": itemgetter(\"input\")}\n",
    ").assign(\n",
    "    answer=(\n",
    "        RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "        | rag_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"‚úÖ RAG-—Ü–µ–ø–æ—á–∫–∞ —Å–æ–±—Ä–∞–Ω–∞ –Ω–∞ LCEL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "926101b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ –Ω–∞ 100 –≤–æ–ø—Ä–æ—Å–∞—Ö...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [18:56<00:00, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "üèÅ –ë–ï–ù–ß–ú–ê–†–ö –ó–ê–í–ï–†–®–ï–ù\n",
      "üìä –¢–æ—á–Ω–æ—Å—Ç—å (Accuracy): 42.00%\n",
      "üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: benchmark_results.csv\n",
      "==============================\n",
      "\n",
      "–ü—Ä–∏–º–µ—Ä—ã –æ—à–∏–±–æ–∫:\n",
      "Q: What is the current market capitalization of TSCO?\n",
      "Truth: 28121638912\n",
      "Pred: I don't know based on the context.\n",
      "--------------------\n",
      "Q: Where is the headquarters of American Tower Corporation (REI located?\n",
      "Truth: Boston, MA\n",
      "Pred: I don't know based on the context.\n",
      "--------------------\n",
      "Q: What is the official website for AbbVie Inc.?\n",
      "Truth: https://www.abbvie.com\n",
      "Pred: I don't know based on the context.\n",
      "--------------------\n",
      "Q: How many full-time employees work for Workday, Inc.?\n",
      "Truth: 20588.0\n",
      "Pred: I don't know based on the context.\n",
      "--------------------\n",
      "Q: What is the stock ticker symbol for Baxter International Inc.?\n",
      "Truth: BAX\n",
      "Pred: I don't know based on the context.\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 3. –õ–æ–≥–∏–∫–∞ –û—Ü–µ–Ω—â–∏–∫–∞ (LLM-as-a-Judge) ---\n",
    "\n",
    "def evaluate_answer(question, ground_truth, prediction):\n",
    "    \"\"\"\n",
    "    –ü—Ä–æ—Å–∏—Ç LLM —Å—Ä–∞–≤–Ω–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: TRUE (–µ—Å–ª–∏ —Å–º—ã—Å–ª —Å–æ–≤–ø–∞–¥–∞–µ—Ç) –∏–ª–∏ FALSE.\n",
    "    \"\"\"\n",
    "    # –ü—Ä–æ–º–ø—Ç –¥–ª—è —Å—É–¥—å–∏\n",
    "    eval_prompt = f\"\"\"\n",
    "    You are a strict evaluator. Compare the predicted answer with the ground truth.\n",
    "    \n",
    "    Question: {question}\n",
    "    Ground Truth: {ground_truth}\n",
    "    Prediction: {prediction}\n",
    "    \n",
    "    Task: Does the Prediction match the factual meaning of the Ground Truth? \n",
    "    Ignore minor phrasing differences.\n",
    "    If the prediction says \"I don't know\", mark it as FALSE.\n",
    "    \n",
    "    Respond with exactly one word: TRUE or FALSE.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = evaluator_llm.invoke(eval_prompt)\n",
    "        content = response.content.strip().upper()\n",
    "        return \"TRUE\" in content\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# --- 4. –ó–∞–ø—É—Å–∫ –ë–µ–Ω—á–º–∞—Ä–∫–∞ ---\n",
    "\n",
    "def run_benchmark():\n",
    "    if not os.path.exists(BENCHMARK_FILE):\n",
    "        print(f\"–§–∞–π–ª {BENCHMARK_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω! –°–Ω–∞—á–∞–ª–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã.\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(BENCHMARK_FILE)\n",
    "    print(f\"üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ –Ω–∞ {len(df)} –≤–æ–ø—Ä–æ—Å–∞—Ö...\")\n",
    "\n",
    "    results = []\n",
    "    correct_count = 0\n",
    "\n",
    "    # –ò—Å–ø–æ–ª—å–∑—É–µ–º tqdm –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        question = row['question']\n",
    "        ground_truth = str(row['ground_truth'])\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # 1. –ó–∞–ø—É—Å–∫ RAG\n",
    "            response = rag_chain.invoke({\"input\": question})\n",
    "            prediction = response['answer']\n",
    "            \n",
    "            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\n",
    "            retrieved_docs = [doc.page_content for doc in response['context']]\n",
    "            context_text = \" || \".join(retrieved_docs) # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π\n",
    "            \n",
    "            # 2. –û—Ü–µ–Ω–∫–∞\n",
    "            is_correct = evaluate_answer(question, ground_truth, prediction)\n",
    "            \n",
    "            if is_correct:\n",
    "                correct_count += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            prediction = f\"ERROR: {e}\"\n",
    "            is_correct = False\n",
    "            context_text = \"\"\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"ground_truth\": ground_truth,\n",
    "            \"prediction\": prediction,\n",
    "            \"is_correct\": is_correct,\n",
    "            \"retrieved_context\": context_text, # –í–∞–∂–Ω–æ –≤–∏–¥–µ—Ç—å, —á—Ç–æ –Ω–∞—à–µ–ª —Ä–µ—Ç—Ä–∏–≤–µ—Ä\n",
    "            \"time_sec\": round(elapsed_time, 2),\n",
    "            \"question_type\": row.get('question_type', 'unknown')\n",
    "        })\n",
    "\n",
    "    # --- 5. –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(RESULTS_FILE, index=False)\n",
    "    \n",
    "    accuracy = (correct_count / len(df)) * 100\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(f\"üèÅ –ë–ï–ù–ß–ú–ê–†–ö –ó–ê–í–ï–†–®–ï–ù\")\n",
    "    print(f\"üìä –¢–æ—á–Ω–æ—Å—Ç—å (Accuracy): {accuracy:.2f}%\")\n",
    "    print(f\"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {RESULTS_FILE}\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    # –í—ã–≤–æ–¥ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –º–µ—Å—Ç (—Ç–æ–ø-5 –æ—à–∏–±–æ–∫)\n",
    "    print(\"\\n–ü—Ä–∏–º–µ—Ä—ã –æ—à–∏–±–æ–∫:\")\n",
    "    errors = results_df[results_df['is_correct'] == False].head(5)\n",
    "    for i, row in errors.iterrows():\n",
    "        print(f\"Q: {row['question']}\")\n",
    "        print(f\"Truth: {row['ground_truth']}\")\n",
    "        print(f\"Pred: {row['prediction']}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_benchmark()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
